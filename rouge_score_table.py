# -*- coding: utf-8 -*-
"""rouge_score_table.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uiiYrJMQ3wR44bqne_Z43X7B8ZLVM9L9
"""

!pip install pandas matplotlib tabulate

!pip install datasets transformers rouge_score

!pip install kaggle

!pip install kagglehub

import kagglehub

# Download dataset using kagglehub
path = kagglehub.dataset_download("gowrishankarp/newspaper-text-summarization-cnn-dailymail")

print("Path to dataset files:", path)

import os

# Specify the path to the directory
directory_path = "/root/.cache/kagglehub/datasets/gowrishankarp/newspaper-text-summarization-cnn-dailymail/versions/2"

# List all files in the directory
files = os.listdir(directory_path)
print(files)

import os

# Specify the path to the cnn_dailymail directory
directory_path = "/root/.cache/kagglehub/datasets/gowrishankarp/newspaper-text-summarization-cnn-dailymail/versions/2/cnn_dailymail"

# List all files in the directory
files = os.listdir(directory_path)
print(files)

import pandas as pd

# Load the training dataset
df_train = pd.read_csv("/root/.cache/kagglehub/datasets/gowrishankarp/newspaper-text-summarization-cnn-dailymail/versions/2/cnn_dailymail/train.csv")

# Check the first few rows of the training dataset
print("Training Data:")
print(df_train.head())

!pip install transformers rouge_score

!pip install --upgrade transformers

!pip install transformers rouge-score

!pip install --upgrade transformers

!pip install transformers==4.28.0

!pip install transformers==4.28.0

!pip install rouge

import pandas as pd
from transformers import T5ForConditionalGeneration, T5Tokenizer
from transformers import BartForConditionalGeneration, BartTokenizer
from transformers import GPT2LMHeadModel, GPT2Tokenizer
from transformers import PegasusForConditionalGeneration, PegasusTokenizer
from transformers import GPTNeoForCausalLM, GPT2Tokenizer
from rouge import Rouge

# Load the dataset
train_df = pd.read_csv("/root/.cache/kagglehub/datasets/gowrishankarp/newspaper-text-summarization-cnn-dailymail/versions/2/cnn_dailymail/train.csv")

# Define the models and tokenizers
models = {
    'T5': (T5ForConditionalGeneration.from_pretrained('t5-small'), T5Tokenizer.from_pretrained('t5-small')),
    'BART': (BartForConditionalGeneration.from_pretrained('facebook/bart-base'), BartTokenizer.from_pretrained('facebook/bart-base')),
    'GPT-2': (GPT2LMHeadModel.from_pretrained('gpt2'), GPT2Tokenizer.from_pretrained('gpt2')),
    'Pegasus': (PegasusForConditionalGeneration.from_pretrained('google/pegasus-xsum'), PegasusTokenizer.from_pretrained('google/pegasus-xsum')),
    'GPT-Neo': (GPTNeoForCausalLM.from_pretrained('EleutherAI/gpt-neo-1.3B'), GPT2Tokenizer.from_pretrained('gpt2')),  # Using GPT2Tokenizer
}

# Initialize ROUGE
rouge = Rouge()

# Initialize a results dictionary
results = {}

# Loop through the models to summarize and evaluate
for model_name, (model, tokenizer) in models.items():
    summaries = []
    for article in train_df['article'].tolist():  # Iterate through articles in your training dataset
        inputs = tokenizer(article, return_tensors="pt", max_length=512, truncation=True)
        outputs = model.generate(**inputs, max_length=150, num_beams=5, early_stopping=True)
        summary = tokenizer.decode(outputs[0], skip_special_tokens=True)
        summaries.append(summary)

    # Calculate ROUGE scores (Replace 'highlights' with the appropriate ground truth column in your dataset)
    scores = rouge.get_s